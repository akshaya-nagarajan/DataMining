{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set  478\n",
      "Length of test set  205\n",
      "Training data benign 314\n",
      "Training data malignant 164\n",
      "df_downsampled_benign 164\n",
      "df_downsampled_malignant 164\n",
      "df_upsampled_benign 314\n",
      "df_upsampled_malignant 314\n",
      "Accuracy of the model 94.6341463414634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[334]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import statsmodels.api as sm\n",
    "\n",
    "# READING THE DOWNLOADED DATA SET SAVED IN THE SYSTEM\n",
    "data_frame = pd.read_csv('~/Desktop/bc.csv')\n",
    "\n",
    "# DELETING THE UNWANTED COLUMNS\n",
    "first_col = data_frame.columns[0]\n",
    "second_col = data_frame.columns[1]\n",
    "data_frame = data_frame.drop([first_col], axis=1)\n",
    "data_frame = data_frame.drop([second_col], axis=1)\n",
    "\n",
    "#ASSIGNING 1 FOR MALIGNANT CLASS AND 0 FOR BENIGN CLASS\n",
    "data_frame['Class'] = [1 if i==\"malignant\" else 0 for i in data_frame.Class]\n",
    "\n",
    "# SEPERATING X AND Y.\n",
    "# X HAVING ALL DATA OTHER THAN IN CLASS COLUMN. Y HAVING ALL DATA IN CLASS COLUMN\n",
    "X = data_frame[['Cl.thickness', 'Cell.size', 'Cell.shape', 'Marg.adhesion', 'Epith.c.size', 'Bare.nuclei', 'Bl.cromatin', 'Normal.nucleoli', 'Mitoses']]\n",
    "y = data_frame['Class']\n",
    "\n",
    "#SPLITTING THE TRAINING AND TEST DATA SET.TRAINING SET BEING 70% AND TEST DATA SET IS 30%\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "# CONCATENATE ALL THE COLUMNS FOR TEST AND TRAINING DATA SET\n",
    "training_data = pd.concat([train_X, train_y], axis=1)\n",
    "test_data = pd.concat([test_X, test_y], axis=1)\n",
    "print(\"Length of training set \", len(train_X))\n",
    "print(\"Length of test set \", len(test_X))\n",
    "\n",
    "# NUMBER OF ROWS WITH BENIGN AS CLASS IS HIGHER COMPARED TO MALIGNANT.SEPARATING BOTH THE CLASSES AND PRINTING THE NUMBER\n",
    "data_frame_majority = training_data[training_data.Class == 0]\n",
    "data_frame_minority = training_data[training_data.Class == 1]\n",
    "print(\"Training data benign\", len(data_frame_majority))\n",
    "print(\"Training data malignant\", len(data_frame_minority))\n",
    "\n",
    "#DOWNSAMPLING\n",
    "df_majority_downsampled = resample(data_frame_majority, replace=False, n_samples=164)\n",
    "df_downsampled = pd.concat([df_majority_downsampled, data_frame_minority])\n",
    "df_downsampled_benign = df_downsampled[df_downsampled.Class == 0]\n",
    "df_downsampled_malignant = df_downsampled[df_downsampled.Class == 1]\n",
    "print(\"df_downsampled_benign\", len(df_downsampled_benign))\n",
    "print(\"df_downsampled_malignant\", len(df_downsampled_malignant))\n",
    "\n",
    "#UPSAMPLING\n",
    "df_minority_upsampled = resample(data_frame_minority, replace=True, n_samples=314)\n",
    "df_upsampled = pd.concat([data_frame_majority, df_minority_upsampled])\n",
    "df_upsampled_benign = df_upsampled[df_upsampled.Class == 0]\n",
    "df_upsampled_malignant = df_upsampled[df_upsampled.Class == 1]\n",
    "print(\"df_upsampled_benign\", len(df_upsampled_benign))\n",
    "print(\"df_upsampled_malignant\", len(df_upsampled_malignant))\n",
    "\n",
    "reg = linear_model.LogisticRegression()\n",
    "# USING TRAINING DATA BELOW\n",
    "# reg.fit(train_X, train_y) \n",
    "# USING DOWNSAMPLED DATA BELOW\n",
    "# reg.fit(df_downsampled.drop('Class', axis=1), df_downsampled.Class)\n",
    "# USING UPSAMPLED DATA BELOW\n",
    "reg.fit(df_upsampled.drop('Class', axis=1), df_upsampled.Class)\n",
    "y_pred = reg.predict(test_X) \n",
    "# GET THE ACCURACY OF THE MODEL\n",
    "print(\"Accuracy of the model\", metrics.accuracy_score(test_y, y_pred)*100)\n",
    "\n",
    "# TRIED GLM FUNCTION\n",
    "#col = df_downsampled.drop('Class', axis=1)\n",
    "#cols = ['Cl.thickness', 'Cell.size','Cell.shape']\n",
    "#model = sm.GLM(df_downsampled.Class, df_downsampled[cols], family=sm.families.Binomial())\n",
    "#result = model.fit()\n",
    "#print(result.summary())\n",
    "#print(result.predict(test_data))\n",
    "#print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
